{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3nD3GjW41pOS2qYSJO5ul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52029-lab/NLP_LAB-ASSIGNMENTS/blob/main/Lab8_NGram_Model_NithinPatil_2403A52029.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ouo0mmzG-I9U"
      },
      "outputs": [],
      "source": [
        "import nltk # Import the Natural Language Toolkit library\n",
        "import re # Import regular expression operations\n",
        "import math # Import mathematical functions\n",
        "import random # Import random number generation functions\n",
        "from collections import defaultdict, Counter # Import defaultdict and Counter from collections module\n",
        "import numpy as np # Import NumPy for numerical operations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Load text file from the specified path\n",
        "with open(\"/content/corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read() # Read the entire content of the file into the 'text' variable\n",
        "\n",
        "print(text[:500])  # Print the first 500 characters of the loaded text for a sample display"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN9xgJjH_Z3j",
        "outputId": "ec6e248a-9999-4d34-d8db-ca430505fe05"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Natural language processing is a subfield of artificial intelligence that focuses on the interaction\n",
            "between computers and human language. It enables machines to read, understand, and generate text\n",
            "in a way that is meaningful. Over the years, natural language processing has evolved rapidly due to\n",
            "advances in machine learning and the availability of large datasets.\n",
            "\n",
            "Language models play a central role in natural language processing. A language model assigns\n",
            "probabilities to sequences of words an\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab') # Download the 'punkt_tab' tokenizer from NLTK data\n",
        "def preprocess_text(text):\n",
        "    text = text.lower() # Convert all text to lowercase\n",
        "    text = re.sub(r'[^a-z\\s]', '', text) # Remove all characters except lowercase letters and spaces\n",
        "    sentences = nltk.sent_tokenize(text) # Tokenize the text into sentences\n",
        "\n",
        "    processed = [] # Initialize an empty list to store processed sentences\n",
        "    for sent in sentences:\n",
        "        words = nltk.word_tokenize(sent) # Tokenize each sentence into words\n",
        "        processed.append(['<s>'] + words + ['</s>']) # Add start (<s>) and end (</s>) tokens to each sentence\n",
        "    return processed # Return the list of processed sentences\n",
        "\n",
        "sentences = preprocess_text(text) # Preprocess the loaded text and store the result in 'sentences'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWJGvhab_tIF",
        "outputId": "aff6e2f0-0048-45b8-c22b-2e4c534fabe7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ngram(sentences, n):\n",
        "    ngrams = [] # Initialize an empty list to store n-grams\n",
        "    for sent in sentences:\n",
        "        ngrams.extend(list(nltk.ngrams(sent, n))) # Generate n-grams for each sentence and add to the list\n",
        "    return Counter(ngrams) # Return a Counter object of the generated n-grams\n",
        "\n",
        "unigram = build_ngram(sentences, 1) # Build unigrams (single words)\n",
        "bigram  = build_ngram(sentences, 2) # Build bigrams (two-word sequences)\n",
        "trigram = build_ngram(sentences, 3) # Build trigrams (three-word sequences)\n",
        "\n",
        "vocab_size = len(unigram) # Calculate the vocabulary size based on unique unigrams"
      ],
      "metadata": {
        "id": "pBhlb__Z_uT3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unigram_prob(word):\n",
        "    # Calculate unigram probability with add-1 smoothing\n",
        "    return (unigram[(word,)] + 1) / (sum(unigram.values()) + vocab_size)\n",
        "\n",
        "def bigram_prob(w1, w2):\n",
        "    # Calculate bigram probability with add-1 smoothing\n",
        "    # The denominator is the count of the first word (w1) plus vocabulary size for smoothing\n",
        "    return (bigram[(w1, w2)] + 1) / (unigram[(w1,)] + vocab_size)\n",
        "\n",
        "def trigram_prob(w1, w2, w3):\n",
        "    # Calculate trigram probability with add-1 smoothing\n",
        "    # The denominator is the count of the bigram (w1, w2) plus vocabulary size for smoothing\n",
        "    return (trigram[(w1, w2, w3)] + 1) / (bigram[(w1, w2)] + vocab_size)"
      ],
      "metadata": {
        "id": "mu026bnm_unf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_probability(sentence, model='bigram'):\n",
        "    # Prepare the sentence by tokenizing and adding start/end tokens\n",
        "    words = ['<s>'] + nltk.word_tokenize(sentence.lower()) + ['</s>']\n",
        "    prob = 1.0 # Initialize probability to 1.0\n",
        "\n",
        "    if model == 'unigram':\n",
        "        for w in words:\n",
        "            prob *= unigram_prob(w) # Multiply by unigram probability of each word\n",
        "\n",
        "    elif model == 'bigram':\n",
        "        for i in range(len(words)-1):\n",
        "            # Multiply by bigram probability of (current_word, next_word)\n",
        "            prob *= bigram_prob(words[i], words[i+1])\n",
        "\n",
        "    elif model == 'trigram':\n",
        "        for i in range(len(words)-2):\n",
        "            # Multiply by trigram probability of (word1, word2, word3)\n",
        "            prob *= trigram_prob(words[i], words[i+1], words[i+2])\n",
        "\n",
        "    return prob # Return the total sentence probability"
      ],
      "metadata": {
        "id": "-NA8UY5S_vMP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"natural language processing is interesting\" # Define a sample sentence\n",
        "print(sentence_probability(sent, \"unigram\")) # Calculate and print sentence probability using unigram model\n",
        "print(sentence_probability(sent, \"bigram\")) # Calculate and print sentence probability using bigram model\n",
        "print(sentence_probability(sent, \"trigram\")) # Calculate and print sentence probability using trigram model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mECAkMkA30t",
        "outputId": "7849ee5e-7fb1-438b-c303-3d7a087f9cba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.732967457781427e-17\n",
            "1.201408259871537e-13\n",
            "5.905932332588356e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(sentence, model='bigram'):\n",
        "    # Prepare the sentence by tokenizing and adding start/end tokens\n",
        "    words = ['<s>'] + nltk.word_tokenize(sentence.lower()) + ['</s>']\n",
        "    log_prob = 0 # Initialize log probability to 0\n",
        "    N = len(words) # Get the number of words in the sentence\n",
        "\n",
        "    if model == 'unigram':\n",
        "        for w in words:\n",
        "            log_prob += math.log(unigram_prob(w)) # Add log unigram probability of each word\n",
        "\n",
        "    elif model == 'bigram':\n",
        "        for i in range(len(words)-1):\n",
        "            # Add log bigram probability of (current_word, next_word)\n",
        "            log_prob += math.log(bigram_prob(words[i], words[i+1]))\n",
        "\n",
        "    elif model == 'trigram':\n",
        "        for i in range(len(words)-2):\n",
        "            # Add log trigram probability of (word1, word2, word3)\n",
        "            log_prob += math.log(trigram_prob(words[i], words[i+1], words[i+2]))\n",
        "\n",
        "    # Calculate perplexity using the formula exp(-log_prob / N)\n",
        "    return math.exp(-log_prob / N)"
      ],
      "metadata": {
        "id": "p3-k7GauA6J1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unigram:\", perplexity(sent, \"unigram\")) # Calculate and print perplexity using unigram model\n",
        "print(\"Bigram :\", perplexity(sent, \"bigram\")) # Calculate and print perplexity using bigram model\n",
        "print(\"Trigram:\", perplexity(sent, \"trigram\")) # Calculate and print perplexity using trigram model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGjmF2vDA6dl",
        "outputId": "1b69f5eb-64d7-4004-80e9-49c89f0be789"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram: 200.29256628401615\n",
            "Bigram : 70.10653194213862\n",
            "Trigram: 40.18848619089582\n"
          ]
        }
      ]
    }
  ]
}